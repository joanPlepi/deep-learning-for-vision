{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple 2d plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-10, 10.2, 0.2)\n",
    "w = 0.5\n",
    "b = 3.0\n",
    "y = w * x + b\n",
    "\n",
    "plt.title(\"y = {} * x + {}\".format(w, b))\n",
    "plt.plot(x, y)\n",
    "plt.xlim(-10, 10)\n",
    "plt.ylim(-10, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given (x, y) pairs, find w and b (in above toy example w=0.5, b=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to training set\n",
    "tensor_x = torch.tensor(x, dtype=torch.float).view(-1, 1)\n",
    "tensor_y = torch.tensor(y, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "# effect of sampling\n",
    "trainloader = DataLoader(TensorDataset(tensor_x, tensor_y), batch_size=len(x), shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight ---> Parameter containing:\n",
      "tensor([[-0.0075]], requires_grad=True)\n",
      "bias ---> Parameter containing:\n",
      "tensor([0.5364], requires_grad=True)\n",
      "Iteration: 2, Loss: 14.82556820\n",
      "Iteration: 3, Loss: 6.72543478\n",
      "Iteration: 4, Loss: 5.68977213\n",
      "Iteration: 5, Loss: 5.38567734\n",
      "Iteration: 6, Loss: 5.16433716\n",
      "Iteration: 7, Loss: 4.95900345\n",
      "Iteration: 8, Loss: 4.76254225\n",
      "Iteration: 9, Loss: 4.57393694\n",
      "Iteration: 10, Loss: 4.39280796\n",
      "Iteration: 11, Loss: 4.21885300\n",
      "Iteration: 12, Loss: 4.05178642\n",
      "Iteration: 13, Loss: 3.89133549\n",
      "Iteration: 14, Loss: 3.73723865\n",
      "Iteration: 15, Loss: 3.58924413\n",
      "Iteration: 16, Loss: 3.44711018\n",
      "Iteration: 17, Loss: 3.31060481\n",
      "Iteration: 18, Loss: 3.17950463\n",
      "Iteration: 19, Loss: 3.05359650\n",
      "Iteration: 20, Loss: 2.93267417\n",
      "Iteration: 21, Loss: 2.81654000\n",
      "Iteration: 22, Loss: 2.70500541\n",
      "Iteration: 23, Loss: 2.59788728\n",
      "Iteration: 24, Loss: 2.49501061\n",
      "Iteration: 25, Loss: 2.39620829\n",
      "Iteration: 26, Loss: 2.30131865\n",
      "Iteration: 27, Loss: 2.21018624\n",
      "Iteration: 28, Loss: 2.12266278\n",
      "Iteration: 29, Loss: 2.03860545\n",
      "Iteration: 30, Loss: 1.95787668\n",
      "Iteration: 31, Loss: 1.88034463\n",
      "Iteration: 32, Loss: 1.80588293\n",
      "Iteration: 33, Loss: 1.73436964\n",
      "Iteration: 34, Loss: 1.66568875\n",
      "Iteration: 35, Loss: 1.59972763\n",
      "Iteration: 36, Loss: 1.53637826\n",
      "Iteration: 37, Loss: 1.47553778\n",
      "Iteration: 38, Loss: 1.41710639\n",
      "Iteration: 39, Loss: 1.36098886\n",
      "Iteration: 40, Loss: 1.30709374\n",
      "Iteration: 41, Loss: 1.25533295\n",
      "Iteration: 42, Loss: 1.20562172\n",
      "Iteration: 43, Loss: 1.15787911\n",
      "Iteration: 44, Loss: 1.11202693\n",
      "Iteration: 45, Loss: 1.06799078\n",
      "Iteration: 46, Loss: 1.02569842\n",
      "Iteration: 47, Loss: 0.98508054\n",
      "Iteration: 48, Loss: 0.94607133\n",
      "Iteration: 49, Loss: 0.90860677\n",
      "Iteration: 50, Loss: 0.87262595\n",
      "Iteration: 51, Loss: 0.83806986\n",
      "Iteration: 52, Loss: 0.80488247\n",
      "Iteration: 53, Loss: 0.77300894\n",
      "Iteration: 54, Loss: 0.74239796\n",
      "Iteration: 55, Loss: 0.71299917\n",
      "Iteration: 56, Loss: 0.68476433\n",
      "Iteration: 57, Loss: 0.65764767\n",
      "Iteration: 58, Loss: 0.63160479\n",
      "Iteration: 59, Loss: 0.60659331\n",
      "Iteration: 60, Loss: 0.58257222\n",
      "Iteration: 61, Loss: 0.55950242\n",
      "Iteration: 62, Loss: 0.53734601\n",
      "Iteration: 63, Loss: 0.51606703\n",
      "Iteration: 64, Loss: 0.49563077\n",
      "Iteration: 65, Loss: 0.47600368\n",
      "Iteration: 66, Loss: 0.45715380\n",
      "Iteration: 67, Loss: 0.43905050\n",
      "Iteration: 68, Loss: 0.42166400\n",
      "Iteration: 69, Loss: 0.40496609\n",
      "Iteration: 70, Loss: 0.38892931\n",
      "Iteration: 71, Loss: 0.37352768\n",
      "Iteration: 72, Loss: 0.35873586\n",
      "Iteration: 73, Loss: 0.34452999\n",
      "Iteration: 74, Loss: 0.33088666\n",
      "Iteration: 75, Loss: 0.31778345\n",
      "Iteration: 76, Loss: 0.30519909\n",
      "Iteration: 77, Loss: 0.29311314\n",
      "Iteration: 78, Loss: 0.28150582\n",
      "Iteration: 79, Loss: 0.27035809\n",
      "Iteration: 80, Loss: 0.25965199\n",
      "Iteration: 81, Loss: 0.24936979\n",
      "Iteration: 82, Loss: 0.23949477\n",
      "Iteration: 83, Loss: 0.23001085\n",
      "Iteration: 84, Loss: 0.22090249\n",
      "Iteration: 85, Loss: 0.21215469\n",
      "Iteration: 86, Loss: 0.20375338\n",
      "Iteration: 87, Loss: 0.19568484\n",
      "Iteration: 88, Loss: 0.18793572\n",
      "Iteration: 89, Loss: 0.18049346\n",
      "Iteration: 90, Loss: 0.17334583\n",
      "Iteration: 91, Loss: 0.16648132\n",
      "Iteration: 92, Loss: 0.15988870\n",
      "Iteration: 93, Loss: 0.15355708\n",
      "Iteration: 94, Loss: 0.14747620\n",
      "Iteration: 95, Loss: 0.14163622\n",
      "Iteration: 96, Loss: 0.13602746\n",
      "Iteration: 97, Loss: 0.13064073\n",
      "Iteration: 98, Loss: 0.12546736\n",
      "Iteration: 99, Loss: 0.12049878\n",
      "Iteration: 100, Loss: 0.11572708\n",
      "Time: 42.74141908\n",
      "Parameter containing:\n",
      "tensor([[0.5000]], requires_grad=True) Parameter containing:\n",
      "tensor([2.6666], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = torch.nn.Linear(1, 1)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, '--->', param)\n",
    "    \n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_iters = 100\n",
    "th = 1e-8\n",
    "err = 10000\n",
    "iter = 1\n",
    "\n",
    "start = time.time()\n",
    "while err >= th and iter < num_iters:\n",
    "    for (tx, ty) in trainloader:\n",
    "        out = model(tx)\n",
    "    \n",
    "        loss = criterion(out, ty)\n",
    "        err = abs(loss.item())\n",
    "        print(\"Iteration: {}, Loss: {:.8f}\".format(iter + 1, err))\n",
    "        iter += 1\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time: {:.8f}\".format(end - start))\n",
    "print(model.weight, model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight ---> Parameter containing:\n",
      "tensor([[-0.0075]], requires_grad=True)\n",
      "bias ---> Parameter containing:\n",
      "tensor([0.5364], requires_grad=True)\n",
      "Iteration: 2, Loss: 14.82556820\n",
      "Iteration: 3, Loss: 6.72543478\n",
      "Iteration: 4, Loss: 5.68977213\n",
      "Iteration: 5, Loss: 5.38567734\n",
      "Iteration: 6, Loss: 5.16433716\n",
      "Iteration: 7, Loss: 4.95900345\n",
      "Iteration: 8, Loss: 4.76254225\n",
      "Iteration: 9, Loss: 4.57393694\n",
      "Iteration: 10, Loss: 4.39280796\n",
      "Iteration: 11, Loss: 4.21885300\n",
      "Iteration: 12, Loss: 4.05178642\n",
      "Iteration: 13, Loss: 3.89133549\n",
      "Iteration: 14, Loss: 3.73723865\n",
      "Iteration: 15, Loss: 3.58924413\n",
      "Iteration: 16, Loss: 3.44711018\n",
      "Iteration: 17, Loss: 3.31060481\n",
      "Iteration: 18, Loss: 3.17950463\n",
      "Iteration: 19, Loss: 3.05359650\n",
      "Iteration: 20, Loss: 2.93267417\n",
      "Iteration: 21, Loss: 2.81654000\n",
      "Iteration: 22, Loss: 2.70500541\n",
      "Iteration: 23, Loss: 2.59788728\n",
      "Iteration: 24, Loss: 2.49501061\n",
      "Iteration: 25, Loss: 2.39620829\n",
      "Iteration: 26, Loss: 2.30131865\n",
      "Iteration: 27, Loss: 2.21018624\n",
      "Iteration: 28, Loss: 2.12266278\n",
      "Iteration: 29, Loss: 2.03860545\n",
      "Iteration: 30, Loss: 1.95787668\n",
      "Iteration: 31, Loss: 1.88034463\n",
      "Iteration: 32, Loss: 1.80588293\n",
      "Iteration: 33, Loss: 1.73436964\n",
      "Iteration: 34, Loss: 1.66568875\n",
      "Iteration: 35, Loss: 1.59972763\n",
      "Iteration: 36, Loss: 1.53637826\n",
      "Iteration: 37, Loss: 1.47553778\n",
      "Iteration: 38, Loss: 1.41710639\n",
      "Iteration: 39, Loss: 1.36098886\n",
      "Iteration: 40, Loss: 1.30709374\n",
      "Iteration: 41, Loss: 1.25533295\n",
      "Iteration: 42, Loss: 1.20562172\n",
      "Iteration: 43, Loss: 1.15787911\n",
      "Iteration: 44, Loss: 1.11202693\n",
      "Iteration: 45, Loss: 1.06799078\n",
      "Iteration: 46, Loss: 1.02569842\n",
      "Iteration: 47, Loss: 0.98508054\n",
      "Iteration: 48, Loss: 0.94607133\n",
      "Iteration: 49, Loss: 0.90860677\n",
      "Iteration: 50, Loss: 0.87262595\n",
      "Iteration: 51, Loss: 0.83806986\n",
      "Iteration: 52, Loss: 0.80488247\n",
      "Iteration: 53, Loss: 0.77300894\n",
      "Iteration: 54, Loss: 0.74239796\n",
      "Iteration: 55, Loss: 0.71299917\n",
      "Iteration: 56, Loss: 0.68476433\n",
      "Iteration: 57, Loss: 0.65764767\n",
      "Iteration: 58, Loss: 0.63160479\n",
      "Iteration: 59, Loss: 0.60659331\n",
      "Iteration: 60, Loss: 0.58257222\n",
      "Iteration: 61, Loss: 0.55950242\n",
      "Iteration: 62, Loss: 0.53734601\n",
      "Iteration: 63, Loss: 0.51606703\n",
      "Iteration: 64, Loss: 0.49563077\n",
      "Iteration: 65, Loss: 0.47600368\n",
      "Iteration: 66, Loss: 0.45715380\n",
      "Iteration: 67, Loss: 0.43905050\n",
      "Iteration: 68, Loss: 0.42166400\n",
      "Iteration: 69, Loss: 0.40496609\n",
      "Iteration: 70, Loss: 0.38892931\n",
      "Iteration: 71, Loss: 0.37352768\n",
      "Iteration: 72, Loss: 0.35873586\n",
      "Iteration: 73, Loss: 0.34452999\n",
      "Iteration: 74, Loss: 0.33088666\n",
      "Iteration: 75, Loss: 0.31778345\n",
      "Iteration: 76, Loss: 0.30519909\n",
      "Iteration: 77, Loss: 0.29311314\n",
      "Iteration: 78, Loss: 0.28150582\n",
      "Iteration: 79, Loss: 0.27035809\n",
      "Iteration: 80, Loss: 0.25965199\n",
      "Iteration: 81, Loss: 0.24936979\n",
      "Iteration: 82, Loss: 0.23949477\n",
      "Iteration: 83, Loss: 0.23001085\n",
      "Iteration: 84, Loss: 0.22090249\n",
      "Iteration: 85, Loss: 0.21215469\n",
      "Iteration: 86, Loss: 0.20375338\n",
      "Iteration: 87, Loss: 0.19568484\n",
      "Iteration: 88, Loss: 0.18793572\n",
      "Iteration: 89, Loss: 0.18049346\n",
      "Iteration: 90, Loss: 0.17334583\n",
      "Iteration: 91, Loss: 0.16648132\n",
      "Iteration: 92, Loss: 0.15988870\n",
      "Iteration: 93, Loss: 0.15355708\n",
      "Iteration: 94, Loss: 0.14747620\n",
      "Iteration: 95, Loss: 0.14163622\n",
      "Iteration: 96, Loss: 0.13602746\n",
      "Iteration: 97, Loss: 0.13064073\n",
      "Iteration: 98, Loss: 0.12546736\n",
      "Iteration: 99, Loss: 0.12049878\n",
      "Iteration: 100, Loss: 0.11572708\n",
      "Time: 0.02991891\n",
      "Parameter containing:\n",
      "tensor([[0.5000]], requires_grad=True) Parameter containing:\n",
      "tensor([2.6666], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = torch.nn.Linear(1, 1)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, '--->', param)\n",
    "    \n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_iters = 100\n",
    "th = 1e-8\n",
    "err = 10000\n",
    "iter = 1\n",
    "\n",
    "start = time.time()\n",
    "while err >= th and iter < num_iters:\n",
    "    \n",
    "    # forward pass full batch\n",
    "    out = model(tensor_x)\n",
    "    \n",
    "    loss = criterion(out, tensor_y)\n",
    "    err = abs(loss.item())\n",
    "    print(\"Iteration: {}, Loss: {:.8f}\".format(iter + 1, err))\n",
    "    iter += 1\n",
    "    \n",
    "    # backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time: {:.8f}\".format(end - start))\n",
    "print(model.weight, model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
