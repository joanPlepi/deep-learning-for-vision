{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2878a2e6cd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set size: 40000, Valid set size: 10000, Test set size: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "\n",
    "# split train set in 0.8/0.2 train/validation sets\n",
    "train_size = int(0.8 * len(trainset))\n",
    "valid_size = len(trainset) - train_size\n",
    "\n",
    "trainset, validset = torch.utils.data.random_split(trainset, [train_size, valid_size])\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "input_dim = 3 * 32 * 32\n",
    "output_dim = 10\n",
    "batch_size = 64\n",
    "\n",
    "print(\"Train set size: {}, Valid set size: {}, Test set size: {}\".format(\n",
    "        len(trainset), len(validset), len(testset)\n",
    "        ))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "def test(model, dataloader, batch_size=32):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            # send to device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return 100 * correct / total;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, stride=1, padding=1), # N x 16 x 32 x 32\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2, stride=2), # N x 16 x 16 x 16\n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=1), # N x 32 x 16 x 16\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, stride=2), # N x 32 x 8 x 8\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32*8*8, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1\\5], loss: 1.8001, iters: 624\n",
      "Epoch: [2\\5], loss: 1.6919, iters: 624\n",
      "Epoch: [3\\5], loss: 1.4898, iters: 624\n",
      "Epoch: [4\\5], loss: 1.3814, iters: 624\n",
      "Epoch: [5\\5], loss: 1.4773, iters: 624\n",
      "Training time: 38.8003\n",
      "Train acc:  50.99\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=0)\n",
    "\n",
    "tic = time.time()\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"Epoch: [{}\\{}], loss: {:.4f}, iters: {}\".format(epoch + 1, epochs, loss.item(), i))\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Training time: {:.4f}\".format(toc - tic))\n",
    "\n",
    "train_acc = test(model, trainloader, batch_size=batch_size)\n",
    "print(\"Train acc: \", train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "batches_x = []\n",
    "batches_y = []\n",
    "i = 0\n",
    "for x, y in trainset:\n",
    "    i += 1\n",
    "    train_x.append(x)\n",
    "    train_y.append(y)\n",
    "    \n",
    "    if i % batch_size == 0:\n",
    "        train_x = torch.stack(train_x).view(batch_size, 3, 32, 32)\n",
    "        train_y = torch.tensor(train_y)\n",
    "        batches_x.append(train_x)\n",
    "        batches_y.append(train_y)\n",
    "        train_x = []\n",
    "        train_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1\\5], loss: 1.8431, iters: 624\n",
      "Epoch: [2\\5], loss: 1.6705, iters: 624\n",
      "Epoch: [3\\5], loss: 1.5499, iters: 624\n",
      "Epoch: [4\\5], loss: 1.4520, iters: 624\n",
      "Epoch: [5\\5], loss: 1.3730, iters: 624\n",
      "Training time: 19.9167\n",
      "Train acc:  51.905\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=0)\n",
    "\n",
    "tic = time.time()\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for i, (images, labels) in enumerate(zip(batches_x, batches_y)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"Epoch: [{}\\{}], loss: {:.4f}, iters: {}\".format(epoch + 1, epochs, loss.item(), i))\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Training time: {:.4f}\".format(toc - tic))\n",
    "\n",
    "train_acc = test(model, trainloader, batch_size=batch_size)\n",
    "print(\"Train acc: \", train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
