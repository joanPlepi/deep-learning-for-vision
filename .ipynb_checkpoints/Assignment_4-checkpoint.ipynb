{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_loader(trainset, testset, batch_size):\n",
    "\n",
    "    # Making dataset iterable\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=trainset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=testset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Parameters:\n",
    "    - k, number of folds\n",
    "    - trainset, the training set\n",
    "    - batch size\n",
    "'''\n",
    "def split_data_in_k_folds(k, trainset, batch_size):\n",
    "    patterns_per_fold = len(trainset) / k\n",
    "\n",
    "    samplers = []\n",
    "    for i in range(k):\n",
    "        samplers.append(SubsetRandomSampler(np.arange(i * patterns_per_fold, (i + 1) * patterns_per_fold, dtype=np.int32)))\n",
    "\n",
    "    all_data_folds = []\n",
    "\n",
    "    for sampler in samplers:\n",
    "        all_data_folds.append(\n",
    "            torch.utils.data.DataLoader(dataset=trainset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        sampler=sampler,\n",
    "                                        shuffle=False)\n",
    "        )\n",
    "\n",
    "    return all_data_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check with Agajan how many layers we can do here...\n",
    "'''\n",
    "Explain the parameters here. \n",
    "in_dim -> cifar case 32x32. I am supposing those are square matrix.\n",
    "d -> stands for depth.\n",
    "'''\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, **params):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=params['d1'], out_channels=params['d2'], kernel_size=params['f1'],\n",
    "                              stride=params['s1'], padding=params['p1'])\n",
    "        # Activation 1\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Max pooling 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        # Convolution 2\n",
    "        self.cnn2 =  nn.Conv2d(in_channels=params['d2'], out_channels=params['d3'], kernel_size=params['f2'],\n",
    "                              stride=params['s2'], padding=params['p2'])\n",
    "        # Activation 2\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # Max pooling 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.W2 = (params['in_dim'] - params['f1'] + 2*params['p1'])/params['s1'] + 1\n",
    "        \n",
    "        self.W3 = ((self.W2 / 2) - params['f2'] + 2*params['p2'])/params['s2'] + 1\n",
    "\n",
    "        self.out_dim = params['d3'] * ((self.W3/2) ** 2)\n",
    "        print(\"For debugging, W2={}, self.W3={} out {}\"\n",
    "              .format(self.W2,self.W3, self.out_dim))\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(int(self.out_dim), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Maybe we use sequential here?\n",
    "        # Convolution and activation 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        # Max pooling 1\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "        # Convolution and activation 1\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Max pooling 2\n",
    "        out = self.maxpool2(out)\n",
    "\n",
    "        # Reshaping to pass it to fc1\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Fully connected layer\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Parameters:\n",
    "        - criterion, loss function\n",
    "        - input dimension\n",
    "        - a numpy array which will save the loss for every epoch\n",
    "        - the model\n",
    "        - number of epochs\n",
    "        - an optimizer\n",
    "        - and the train loader to iterate through the patterns     \n",
    "'''\n",
    "def train(criterion, model, num_epochs, optimizer, train_loader):\n",
    "    loss_per_iter = []\n",
    "    loss_per_epoch = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        tic = time()\n",
    "        loss_acc_per_epoch = 0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # send to device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Clearing the gradients.\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Here the loss function is applied.\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # We accumulate the loss till the end of the epoch\n",
    "            loss_acc_per_epoch += loss\n",
    "            loss_per_iter.append(loss)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "        loss_per_epoch.append(loss_acc_per_epoch/i)\n",
    "        print(\"Finished epoch {:d}/{:d}  in {:f} sec. Loss is {:f}\".format(epoch+1, num_epochs, time() - tic, loss_acc_per_epoch/i))\n",
    "        \n",
    "    return loss_per_epoch, loss_per_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    # Calculate Accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate through test dataset\n",
    "    for images, labels in test_loader:\n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(images)\n",
    "        # Get predictions from the maximum value\n",
    "        # it returns the values and the indices of max values per row. Pretty cool.\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Total number of labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Total correct predictions\n",
    "        correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print('Accuracy: {}'.format(accuracy))\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "''' Loading the dataset '''\n",
    "trainset = dsets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset = dsets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "''' Defining batch size and number of iterations and number of epochs based on those'''\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "\n",
    "# setting the seed\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# setting input and output dimensions\n",
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "input_dim = 3 * 32 * 32\n",
    "output_dim = len(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 16 32\n",
      "For debugging, W2=32.0, self.W3=16.0 out 2048.0\n",
      "CNNModel(\n",
      "  (cnn1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader = get_train_test_loader(trainset, testset, batch_size)\n",
    "\n",
    "parameters = {\n",
    "    'in_dim': 32, \n",
    "    'd1' : 3,\n",
    "    'd2' : 16,\n",
    "    'f1' : 5,\n",
    "    's1' : 1,\n",
    "    'p1' : 2, # lets try it once\n",
    "    'd3' : 32,\n",
    "    'f2' : 5,\n",
    "    's2' : 1,\n",
    "    'p2' : 2\n",
    "}\n",
    "\n",
    "model = CNNModel(**parameters)\n",
    "model.to(device)\n",
    "print(model)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_SGD = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 1/5  in 146.202446 sec. Loss is 2.304501\n",
      "Finished epoch 2/5  in 141.755111 sec. Loss is 2.307823\n",
      "Finished epoch 3/5  in 145.654112 sec. Loss is 2.307734\n",
      "Finished epoch 4/5  in 153.880002 sec. Loss is 2.307858\n",
      "Finished epoch 5/5  in 149.831531 sec. Loss is 2.307914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor(2.3045, grad_fn=<DivBackward0>),\n",
       "  tensor(2.3078, grad_fn=<DivBackward0>),\n",
       "  tensor(2.3077, grad_fn=<DivBackward0>),\n",
       "  tensor(2.3079, grad_fn=<DivBackward0>),\n",
       "  tensor(2.3079, grad_fn=<DivBackward0>)],\n",
       " [tensor(2.3062, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3037, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2974, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2838, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3269, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2890, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2814, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2549, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2685, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2817, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2783, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2444, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2554, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2236, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1730, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1831, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2878, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1995, grad_fn=<NllLossBackward>),\n",
       "  tensor(4.2619, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3049, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2983, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3026, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3009, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2896, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3117, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3126, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3075, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3107, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2972, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2934, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3045, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2930, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2974, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3016, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3089, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2973, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2749, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3260, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2958, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2992, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3041, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2925, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2807, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2818, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3102, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2924, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2763, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2876, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2832, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2665, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2445, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3050, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2764, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2908, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2942, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2648, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2557, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2805, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2471, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2402, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2771, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2442, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2818, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2665, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2149, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.5417, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2489, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2896, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3400, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2630, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2538, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2477, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2729, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2896, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2569, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2613, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2825, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2549, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2956, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2412, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2138, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2561, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2380, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2346, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2503, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2768, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2133, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1924, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2072, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2241, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1357, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2913, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2252, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2372, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2274, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1823, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2912, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1777, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2553, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2099, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2116, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2039, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1309, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.0995, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1604, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.0485, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1043, grad_fn=<NllLossBackward>),\n",
       "  tensor(3.3525, grad_fn=<NllLossBackward>),\n",
       "  tensor(4.1352, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2961, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3102, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3193, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2999, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2898, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2607, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3527, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2722, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2779, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2712, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3063, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2955, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2688, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2623, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2658, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2877, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2453, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2848, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2645, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2516, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2025, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2397, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2403, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2432, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2258, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1859, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1790, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2338, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1990, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2418, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2489, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1813, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2347, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1396, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1912, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2153, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2119, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2061, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2085, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1921, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2533, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2052, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.1549, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3506, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2845, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3367, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3058, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3188, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3062, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3176, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3185, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3308, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3189, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3236, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2904, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3398, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3142, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3247, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3310, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3290, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3065, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3117, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3140, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3119, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3328, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3118, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3169, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2996, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3496, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3027, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2913, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3150, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3414, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3185, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3259, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3134, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2880, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3005, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3130, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3053, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3063, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3070, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3076, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3016, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3140, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2938, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3127, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3015, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3074, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3014, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2926, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3018, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2960, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3157, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3003, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3140, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3082, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2981, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3115, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3079, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2893, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3044, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2927, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2975, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3057, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2960, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3048, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3072, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3100, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3033, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3117, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3081, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3015, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3020, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2960, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2946, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3116, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2975, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2987, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3040, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3076, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3018, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3142, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2963, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3184, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3002, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2998, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3078, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3070, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3068, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3059, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3102, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3043, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2986, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2953, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2985, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3041, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3044, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3135, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3041, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3068, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2992, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3023, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2984, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2996, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3085, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3092, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3033, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3062, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3049, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3063, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3033, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2938, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2976, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3129, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3027, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3005, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3045, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2991, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3012, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3061, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2997, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2996, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2985, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3048, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3027, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2948, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3055, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3072, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3000, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3078, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3110, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2963, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3050, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3022, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3039, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2975, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3007, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2994, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3041, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3022, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3073, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2988, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2949, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3067, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3116, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3040, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3052, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3001, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3056, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3055, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3084, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3013, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3068, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2979, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2981, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3074, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3057, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3120, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3002, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3039, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3029, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3005, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3068, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2995, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3046, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3092, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3015, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3070, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3038, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3056, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2996, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2978, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3038, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2995, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3039, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3020, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3008, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3016, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2979, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3081, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3075, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3057, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3020, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3056, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3052, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3005, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3015, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3093, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3053, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3014, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3040, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2986, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3044, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3073, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3114, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3000, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3013, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3053, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3045, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3023, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3049, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3012, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3023, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3018, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3025, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3014, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3052, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3025, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3053, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3018, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3063, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3051, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3043, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3015, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3055, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2962, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3097, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3029, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2995, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3026, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2981, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3038, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3038, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3045, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2991, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3023, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3014, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3087, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3070, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2987, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3004, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3037, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2988, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3055, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3045, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3071, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2974, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3102, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3001, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3056, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2967, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3023, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3005, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3050, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3055, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3009, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3009, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3001, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3029, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2969, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3120, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3078, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2972, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3056, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3005, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3056, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3056, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3071, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3051, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2990, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3046, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2953, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2959, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2993, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3009, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2997, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3071, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2929, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3055, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3083, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2944, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3053, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3047, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2974, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3052, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3083, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3025, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3063, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3082, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3092, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3057, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3054, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3024, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2992, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3027, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3053, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2994, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2995, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3072, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3001, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2996, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2994, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3008, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3004, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3082, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3039, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3025, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3090, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3048, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3037, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3053, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2992, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3068, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3078, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2992, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3084, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3052, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3049, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3009, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3007, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3059, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3026, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3018, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3065, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3082, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3091, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2964, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3051, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3036, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3015, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3045, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3012, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3023, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3040, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3010, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3003, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3013, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3043, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3060, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2971, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3057, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3049, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3058, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2983, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2989, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3048, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3002, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3061, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3001, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3038, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3020, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3075, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3078, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3036, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3081, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3045, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3041, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3036, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3056, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3020, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3061, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3043, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3038, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3030, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3048, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3042, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3056, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3030, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3027, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3001, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3020, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3027, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3018, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3039, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3008, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2975, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3044, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3037, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3024, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3050, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3038, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3014, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3038, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3046, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3058, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3135, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3008, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3057, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3024, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3040, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3023, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3022, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3013, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2988, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3026, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3041, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3022, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3095, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3065, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3024, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2967, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3073, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3071, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3050, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3001, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3060, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2990, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2986, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3081, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3071, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3030, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3047, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2968, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3071, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3066, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3048, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3030, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2988, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3017, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3085, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3071, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3026, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3039, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3047, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3014, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3029, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3050, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3015, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2979, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3012, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3062, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3072, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2997, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3090, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3008, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3041, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3094, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3005, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3002, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3036, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3022, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3043, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3042, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3049, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3022, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2994, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2978, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3042, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3014, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3027, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2975, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3066, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2986, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3045, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2985, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2989, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3068, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3046, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3002, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3077, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3084, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3041, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3087, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3046, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3067, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3087, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3042, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3062, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3033, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3062, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3004, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3008, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3003, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3055, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3044, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3039, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3013, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3052, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2988, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3069, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3023, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3050, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3020, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3000, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3026, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3064, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3045, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3014, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3033, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3008, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3049, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2982, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3066, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3057, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3054, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3024, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3030, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3000, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2946, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3024, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2997, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3062, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3050, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3007, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3049, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3066, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3047, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3037, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3016, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3099, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3056, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3042, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3055, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3054, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3039, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3013, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2986, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3079, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3041, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2992, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3009, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2981, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3110, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3086, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3038, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3007, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3058, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3063, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3060, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3019, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3039, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3004, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3068, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2992, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2986, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3007, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3026, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2997, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3036, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3037, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2999, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3015, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3022, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3058, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3026, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3051, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3054, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3060, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3001, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3049, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3044, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3023, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2991, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3024, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3064, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2970, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3037, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3080, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3062, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3029, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3085, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3005, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3026, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3057, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2999, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3068, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3058, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3020, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3054, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3042, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3055, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3044, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3025, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3049, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3015, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2996, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3064, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3029, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3027, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3002, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3095, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3015, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3020, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3010, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3008, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2993, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3000, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3129, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2990, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3037, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3042, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3090, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3022, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3015, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2986, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3051, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3004, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2968, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3024, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3002, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3060, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3083, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2994, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3079, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3042, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3052, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2983, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3067, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3089, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2981, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2942, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3069, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2998, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3030, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3025, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3041, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3140, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3016, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3022, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3081, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2996, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3041, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2964, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3037, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3001, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3128, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3039, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2974, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3066, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3073, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3049, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3024, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3042, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3063, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3016, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3068, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2989, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2995, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3026, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3025, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3069, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3082, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3043, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3038, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2989, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3040, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3013, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3069, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3043, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3065, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3024, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3037, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3028, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3074, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3044, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3046, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3057, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2990, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2982, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2999, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3008, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2990, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3058, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2953, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3078, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3033, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3047, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3077, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2986, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3065, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2989, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2996, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3010, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3058, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2972, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3135, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3007, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3018, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3085, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2973, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3098, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3020, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2981, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3009, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2998, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2949, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3088, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3076, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3026, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3019, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3066, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2949, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3030, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3060, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3041, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3082, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3032, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3046, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3052, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3085, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2985, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3017, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3054, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3093, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3022, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3069, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3064, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3044, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3025, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2993, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2999, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2992, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3006, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3010, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3047, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3046, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3066, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3052, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3016, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3027, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3073, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3052, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3039, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3019, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3015, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2989, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3054, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3011, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3013, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2998, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3031, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3038, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3029, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3054, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3034, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3012, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3030, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3045, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.2987, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3066, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3009, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3052, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3064, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3063, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3035, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3046, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3024, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3048, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3058, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3050, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3036, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3050, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3022, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3021, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3062, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3001, grad_fn=<NllLossBackward>),\n",
       "  tensor(2.3013, grad_fn=<NllLossBackward>),\n",
       "  ...])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(criterion, model, 5, optimizer_SGD, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
