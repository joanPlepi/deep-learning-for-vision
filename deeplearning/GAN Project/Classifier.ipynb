{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%shell\n",
    "chmod +x organize_food101.sh\n",
    "./organize_food101.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lr_model import LRModel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'folder'\n",
    "dataroot = 'food-101'\n",
    "workers = 2\n",
    "batchSize = 64\n",
    "imageSize = 64\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "niter = 25\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "ngpu = 1\n",
    "netGPath = ''\n",
    "netDPath = ''\n",
    "outf = ''\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the food dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "dataroot = 'food-101/images'\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "                                   transforms.Resize(imageSize),\n",
    "                                   transforms.CenterCrop(imageSize),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ]),\n",
    "    'test': transforms.Compose([\n",
    "                                   transforms.Resize(imageSize),\n",
    "                                   transforms.CenterCrop(imageSize),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: dset.ImageFolder(os.path.join(dataroot, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_loss(scores, targets, margin=1):\n",
    "    \"\"\"Computes SVM loss.\n",
    "    \n",
    "    Args:\n",
    "        scores: `torch.tensor` of shape (num_examples, dimension)\n",
    "        targets: `torch.tensor` of size (num_examples)\n",
    "    \n",
    "    Returns: Cross SVM Loss\n",
    "    \"\"\"\n",
    "    N = scores.shape[0]\n",
    "    correct_scores = scores[range(N), targets].view(-1, 1)\n",
    "    margins = torch.clamp(scores - correct_scores + margin, min=0.0)\n",
    "    margins[range(N), targets] = 0\n",
    "    loss = torch.sum(margins) / N\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader,model_svm, lr=0.001, momentum=0.9, batch_size=64, epochs=10, reg_strength=0.003):\n",
    "\n",
    "    # create optimizer\n",
    "    optimizer = optim.SGD(model_svm.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    num_iters = 0\n",
    "    losses = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            images = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "\n",
    "\n",
    "            svm_inputs = model.extract_features(images)\n",
    "\n",
    "            svm_out = model_svm(svm_inputs)\n",
    "\n",
    "\n",
    "            # forward, backward and optimize\n",
    "            outputs = model_svm(svm_inputs)\n",
    "            loss = svm_loss(outputs, labels)\n",
    "            \n",
    "            # add regularization, only for weights not for biases\n",
    "            regW = 0\n",
    "            for p in model.named_parameters():\n",
    "                if p[0].endswith('weight'):\n",
    "                    regW += torch.sum(p[1]**2)\n",
    "            loss += reg_strength * regW\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Total number of labels\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Total correct predictions\n",
    "            correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "\n",
    "            \n",
    "            num_iters += 1\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # print statistics every 1000th iteration\n",
    "            if num_iters % 1000 == 0:       \n",
    "                accuracy = 100 * correct.double() / total\n",
    "                print('Iteration: {0}, Epoch: {1}, loss: {2:.3f}, Accuracy: {3:.2f}'.format(num_iters, epoch, loss.item(), accuracy.item()))\n",
    "                \n",
    "    \n",
    "    # losses per iteration\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = utils.getDiscriminatorModel(netDpath='netD_cifar.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = LRModel(15360, 101, 5000)\n",
    "model_svm.to(device)\n",
    "losses = train(model=netD2, dataloader=dataloaders['train'],model_svm=model_svm, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
