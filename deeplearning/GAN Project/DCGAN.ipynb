{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "q3NFTLaYpA_7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oXj-1w4ft_it",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Downloading and organizing script for conference room dataset "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ROx6ye5S6is3",
        "outputId": "f79dc05c-91cb-4ff6-c6a9-72099ea839c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fyu/lsun.git\n",
        "!python2.7 lsun/download.py -c conference_room\n",
        "!unzip conference_room_train_lmdb\n",
        "!unzip conference_room_val_lmdb\n",
        "!mkdir data\n",
        "!mv conference_room_train_lmdb data\n",
        "!mv conference_room_val_lmdb data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  conference_room_train_lmdb.zip\n",
            "   creating: conference_room_train_lmdb/\n",
            "  inflating: conference_room_train_lmdb/lock.mdb  \n",
            "  inflating: conference_room_train_lmdb/data.mdb  \n",
            "mv: cannot stat 'conference_room_val_lmdb': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FR42NVISorNb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Downloading and organizing script for the FOOD-101"
      ]
    },
    {
      "metadata": {
        "id": "BBn3f_ON6dcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "3dacf65e-9f44-4bcc-eeed-e78a603cc4c6"
      },
      "cell_type": "code",
      "source": [
        "!wget \"http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\"\n",
        "!tar -xvzf food-101.tar.gz"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-05 12:21:33--  http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.162\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz [following]\n",
            "--2019-01-05 12:21:34--  https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4996278331 (4.7G) [application/x-gzip]\n",
            "Saving to: ‘food-101.tar.gz’\n",
            "\n",
            "food-101.tar.gz     100%[===================>]   4.65G  1.27MB/s    in 60m 55s \n",
            "\n",
            "2019-01-05 13:22:29 (1.30 MB/s) - ‘food-101.tar.gz’ saved [4996278331/4996278331]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e12_VEZMuUcR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Downloading and organizing script for the IMAGENET"
      ]
    },
    {
      "metadata": {
        "id": "_EvEdw5UuakB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mkdir train && mv ILSVRC2012_img_train.tar train/ && cd train\n",
        "tar -xvf ILSVRC2012_img_train.tar && rm -f ILSVRC2012_img_train.tar\n",
        "find . -name \"*.tar\" | while read NAME ; do mkdir -p \"${NAME%.tar}\"; tar -xvf \"${NAME}\" -C \"${NAME%.tar}\"; rm -f \"${NAME}\"; done\n",
        "cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HLbq1kO35cSU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4f0db9b7-1e34-4db6-8e41-3b70dbcaf6b2"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "\n",
        "#parser = argparse.ArgumentParser()\n",
        "#parser.add_argument('--dataset', required=True, help='cifar10 | lsun | mnist |imagenet | folder | lfw | fake')\n",
        "#parser.add_argument('--dataroot', required=True, help='path to dataset')\n",
        "#parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)\n",
        "#parser.add_argument('--batchSize', type=int, default=64, help='input batch size')\n",
        "#parser.add_argument('--imageSize', type=int, default=64, help='the height / width of the input image to network')\n",
        "#parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')\n",
        "#parser.add_argument('--ngf', type=int, default=64)\n",
        "#parser.add_argument('--ndf', type=int, default=64)\n",
        "#parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')\n",
        "#parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
        "#parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
        "#parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
        "#parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n",
        "#parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")\n",
        "#parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n",
        "#parser.add_argument('--outf', default='.', help='folder to output images and model checkpoints')\n",
        "#parser.add_argument('--manualSeed', type=int, help='manual seed')\n",
        "\n",
        "dataset_name = 'folder'\n",
        "dataroot = 'food-101'\n",
        "workers = 2\n",
        "batchSize = 64\n",
        "imageSize = 64\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "niter = 25\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "ngpu = 1\n",
        "netGPath = ''\n",
        "netDPath = ''\n",
        "outf = ''\n",
        "torch.manual_seed(1)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "    \n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "if dataset_name in ['imagenet', 'folder', 'lfw']:\n",
        "    # folder dataset\n",
        "    dataset = dset.ImageFolder(root=dataroot,\n",
        "                               transform=transforms.Compose([\n",
        "                                   transforms.Resize(imageSize),\n",
        "                                   transforms.CenterCrop(imageSize),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                               ]))\n",
        "    nc=3\n",
        "elif dataset_name == 'lsun':\n",
        "    dataset = dset.LSUN(root=dataroot, classes=['conference_room_train'],\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.Resize(imageSize),\n",
        "                            transforms.CenterCrop(imageSize),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                        ]))\n",
        "    nc=3\n",
        "elif dataset_name == 'cifar10':\n",
        "    dataset = dset.CIFAR10(root=dataroot, download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(imageSize),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "    nc=3\n",
        "\n",
        "elif dataset_name == 'mnist':\n",
        "        dataset = dset.MNIST(root=dataroot, download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(imageSize),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5,), (0.5,)),\n",
        "                           ]))\n",
        "        nc=1\n",
        "\n",
        "elif dataset_name == 'fake':\n",
        "    dataset = dset.FakeData(image_size=(3, imageSize, imageSize),\n",
        "                            transform=transforms.ToTensor())\n",
        "    nc=3\n",
        "print(dataset)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 101000\n",
            "    Root Location: food-101\n",
            "    Transforms (if any): Compose(\n",
            "                             Resize(size=64, interpolation=PIL.Image.BILINEAR)\n",
            "                             CenterCrop(size=(64, 64))\n",
            "                             ToTensor()\n",
            "                             Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "                         )\n",
            "    Target Transforms (if any): None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "E9vt6apD5exn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert dataset\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize,\n",
        "                                         shuffle=True, num_workers=int(workers))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "ngpu = int(ngpu)\n",
        "nz = int(nz)\n",
        "ngf = int(ngf)\n",
        "ndf = int(ndf)\n",
        "\n",
        "\n",
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BroK2gN35uTj",
        "outputId": "f8b9ffed-816d-4c26-82a5-41e7d6708a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "        return output\n",
        "\n",
        "\n",
        "netG = Generator(ngpu).to(device)\n",
        "netG.apply(weights_init)\n",
        "if netGPath != '':\n",
        "    netG.load_state_dict(torch.load(netGPath))\n",
        "print(netG)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace)\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t9iX_YJo5wSd",
        "outputId": "530b14fe-179d-4124-c213-1fb0e3d3d1e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "\n",
        "        return output.view(-1, 1).squeeze(1)\n",
        "\n",
        "\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "netD.apply(weights_init)\n",
        "if netDPath != '':\n",
        "    netD.load_state_dict(torch.load(netDPath))\n",
        "print(netD)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sl3o2Vz3KoQK",
        "outputId": "2b212c47-5426-4b19-fc30-ad194e94efd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pillow==4.1.1\n",
        "%reload_ext autoreload\n",
        "%autoreload\n",
        "device"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.1.1) (0.46)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 5.4.0\n",
            "    Uninstalling Pillow-5.4.0:\n",
            "      Successfully uninstalled Pillow-5.4.0\n",
            "Successfully installed pillow-4.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-cX2bAsh587W",
        "outputId": "87ed683b-eebe-4254-dbf6-dede3f85877e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise = torch.randn(batchSize, nz, 1, 1, device=device)\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "# setup optimizer\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "for epoch in range(niter):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        # train with real\n",
        "        netD.zero_grad()\n",
        "        real_cpu = data[0].to(device)\n",
        "        batch_size = real_cpu.size(0)\n",
        "        label = torch.full((batch_size,), real_label, device=device)\n",
        "\n",
        "        output = netD(real_cpu)\n",
        "        errD_real = criterion(output, label)\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        # train with fake\n",
        "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        output = netD(fake.detach())\n",
        "        errD_fake = criterion(output, label)\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        output = netD(fake)\n",
        "        errG = criterion(output, label)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 100 == 0: \n",
        "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, niter, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "        if i % 100 == 0:\n",
        "            vutils.save_image(real_cpu,\n",
        "                    '%s/real_samples.png' % outf,\n",
        "                    normalize=True)\n",
        "            fake = netG(fixed_noise)\n",
        "            vutils.save_image(fake.detach(),\n",
        "                    '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n",
        "                    normalize=True)\n",
        "\n",
        "    # do checkpointing\n",
        "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
        "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0/25][0/1579] Loss_D: 1.6458 Loss_G: 5.9732 D(x): 0.5132 D(G(z)): 0.4913 / 0.0040\n",
            "[0/25][100/1579] Loss_D: 0.3702 Loss_G: 8.7651 D(x): 0.8923 D(G(z)): 0.1503 / 0.0002\n",
            "[0/25][200/1579] Loss_D: 0.7692 Loss_G: 6.6412 D(x): 0.9666 D(G(z)): 0.4194 / 0.0019\n",
            "[0/25][300/1579] Loss_D: 0.0878 Loss_G: 5.7863 D(x): 0.9733 D(G(z)): 0.0563 / 0.0038\n",
            "[0/25][400/1579] Loss_D: 0.7717 Loss_G: 6.0496 D(x): 0.8882 D(G(z)): 0.3959 / 0.0036\n",
            "[0/25][500/1579] Loss_D: 0.4295 Loss_G: 2.6127 D(x): 0.8205 D(G(z)): 0.1516 / 0.1271\n",
            "[0/25][600/1579] Loss_D: 0.3510 Loss_G: 4.2467 D(x): 0.8777 D(G(z)): 0.1786 / 0.0185\n",
            "[0/25][700/1579] Loss_D: 2.4909 Loss_G: 6.6034 D(x): 0.1738 D(G(z)): 0.0008 / 0.0139\n",
            "[0/25][800/1579] Loss_D: 0.5943 Loss_G: 4.8735 D(x): 0.9447 D(G(z)): 0.3671 / 0.0119\n",
            "[0/25][900/1579] Loss_D: 0.2647 Loss_G: 5.5371 D(x): 0.8159 D(G(z)): 0.0220 / 0.0057\n",
            "[0/25][1000/1579] Loss_D: 0.5423 Loss_G: 10.9371 D(x): 0.9268 D(G(z)): 0.2915 / 0.0000\n",
            "[0/25][1100/1579] Loss_D: 0.4839 Loss_G: 3.1718 D(x): 0.7367 D(G(z)): 0.0822 / 0.0802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hFpOOkDJKKXb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}